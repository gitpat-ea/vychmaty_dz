{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6efe46f",
   "metadata": {
    "id": "f2emWlFquBMg"
   },
   "source": [
    "## Домашнее задание\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a42fc60",
   "metadata": {
    "id": "tvwV0vXR3LiS"
   },
   "source": [
    "### 1. Локализация корней.\n",
    "\n",
    "Локализовать действительные корни в уравнении:\n",
    "\n",
    "$$\n",
    "f(x)=20 x^{3} - 4 x^{2} - 5 x + 1 .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc9f4c1",
   "metadata": {},
   "source": [
    "$\\left|a_{n}\\right|$ = 1\n",
    "$\\left|a_{0}\\right|$ = 20\n",
    "\n",
    "A = 5\n",
    "\n",
    "B = 20\n",
    "\n",
    "$\\frac{1}{21} \\leq \\left|x_{0}\\right| \\leq \\frac{5}{4}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e50cd2",
   "metadata": {
    "id": "4Rptf0343R3g"
   },
   "source": [
    "### 2. Порядок сходимости итерационного метода.\n",
    "\n",
    "Определить порядок сходимости итерационного метода при вычислении квадратного корня $x^* = \\sqrt a$ :\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "x_{n+1}=x_n - \\frac{11x_n^4 - 4x_n^2 a + a^2}{16 x_n^5} (x_n^2 - a)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bfd02a",
   "metadata": {},
   "source": [
    "Сдавал, как летучку"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40df4721",
   "metadata": {
    "id": "D26IM4_MuBMg"
   },
   "source": [
    "\n",
    "\n",
    "### 3. Метод Ньютона и Гаусса-Ньютона.\n",
    "\n",
    "Решение проблемы многомерной линейной регрессии нормальным уравнением очень похоже на обобщение метода Ньютона на многомерный случай. Но это не так.\n",
    "Укажите, в чём различие между методами. В одномерном случае\n",
    "\n",
    "$$\n",
    "f(x) \\approx f(x_0) + f^{\\prime}(x_0)(x - x_0) = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "x =  x_0 - \\frac{f(x_0)}{f^{\\prime}(x_0)}\n",
    "$$\n",
    "\n",
    "Обобщение метода Ньютона на многомерный случай выглядит так.\n",
    "\n",
    "$$\n",
    "F(\\vec{β}) \\approx F(\\vec{β^{(0)}}) + \\sum\\limits_{i=1}^n{\\frac{∂F(\\vec{β^{(0)}})}{∂β_i}(β_i - β^0_i)} = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "F(\\vec{β^{(0)}}) + \\nabla F(\\vec{β^{(0)}})\\vec{p}   = 0\n",
    "$$\n",
    "\n",
    "В случае поиска минимума функции F к нулю приравниваем частные производные F\n",
    "$$\n",
    "\\frac{∂F(\\vec{β})}{∂β_i} \\approx \\frac{∂F(\\vec{β^{(0)}})}{∂β_i} + \\sum\\limits_{j=1}^n{\\frac{∂^2F(\\vec{β^{(0)}})}{∂β_i∂β_j}(β_i - β^0_i)} = 0\n",
    "$$\n",
    "\n",
    "Хинт: покажите, что\n",
    "\n",
    "$$\n",
    "2J^TJ  \\neq   H_{ij}\n",
    "$$\n",
    "\n",
    "$H_{ij}$ - гессиан F.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d648fef3",
   "metadata": {},
   "source": [
    "Метод Ньютона для многомерного случая\n",
    "\n",
    "Метод Ньютона расширяется на многомерный случай, предполагая, что мы имеем систему уравнений, которые нужно решить. Для многомерного метода Ньютона мы вычисляем градиент $ \\nabla F(\\beta^{(0)})$  и Гессиан  $H_{ij} = \\frac{\\partial^2 F(\\beta^{(0)})}{\\partial \\beta_i \\partial \\beta_j}$  функции  F . Это позволяет более точно перемещаться к минимуму функции, учитывая кривизну функции, которую описывает гессиан. В этом случае обновление параметров выглядит так:\n",
    "\n",
    "\n",
    "$\\beta^{(1)} = \\beta^{(0)} - H^{-1} \\nabla F(\\beta^{(0)})$\n",
    "\n",
    "\n",
    "Метод Гаусса-Ньютона\n",
    "\n",
    "Метод Гаусса-Ньютона, напротив, является аппроксимацией метода Ньютона и обычно используется для задач нелинейной наименьших квадратов, таких как многомерная линейная регрессия. Вместо гессиана, который может быть сложным и ресурсоемким для вычисления, метод Гаусса-Ньютона использует приближение, основанное на матричном якобиане  J  функции  F  для вычисления параметров. Аппроксимация гессиана при этом выглядит как:\n",
    "\n",
    "\n",
    "$H \\approx 2 J^T J$\n",
    "\n",
    "\n",
    "где  J  — якобиан функции  F  по параметрам  $\\beta$ . Заметим, что $ 2J^T J \\neq H $ — это только приближение, что является основным различием между методами.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72fb65c",
   "metadata": {
    "id": "nZsyCInEuBMm"
   },
   "source": [
    "### 4. Зри в корень\n",
    "\n",
    "Отделить корни следующих уравнений, а затем уточнить один из них с помощью подходящего итерационно процесса (любых двух на ваш выбор двумя разными методами):\n",
    "\n",
    "\n",
    "a) $(0.5)^x+1=(x-1)^2$,\n",
    "\n",
    "__b)__ $(x-3) \\cos x=1, \\quad-2 \\pi \\leq \\mathrm{x} \\leq 2 \\pi$,\n",
    "\n",
    "c) $\\operatorname{arctg}(x-1)+2 x=0$,\n",
    "\n",
    "__d)__ $x^2-20 \\sin x=0$\n",
    "\n",
    "e) $2 \\operatorname{tg} x-x / 2+1=0$,\n",
    "\n",
    "__f)__ $2 \\lg x-x / 2+1=0$,\n",
    "\n",
    "g) $x^2-e^x / 5=0$\n",
    "\n",
    "__h)__ $\\ln x+(x-1)^3=0$,\n",
    "\n",
    "i) $x 2^x=1$\n",
    "\n",
    "__j)__ $(x+1)^{0.5}=1 / x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0414fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.641185744503673,\n",
       " 0.641185744504986,\n",
       " -0.5713179028334707,\n",
       " -0.5713179028318801)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import bisect, newton\n",
    "\n",
    "# Определим функции для уравнений i и e\n",
    "def f_i(x):\n",
    "    return x * 2**x - 1\n",
    "\n",
    "def f_i_prime(x):\n",
    "    return 2**x * (1 + x * np.log(2))\n",
    "\n",
    "def f_e(x):\n",
    "    return 2 * np.tan(x) - x / 2 + 1\n",
    "\n",
    "interval_i = (0, 1)  # Для уравнения i, очевидно, корень лежит между 0 и 1\n",
    "interval_e = (-1, 1)  # Для уравнения e выберем интервал, избегая разрывов тангенса\n",
    "\n",
    "# Найдем корни методом дихотомии\n",
    "root_i_bisect = bisect(f_i, *interval_i)\n",
    "root_e_bisect = bisect(f_e, *interval_e)\n",
    "\n",
    "# Найдем корни методом Ньютона\n",
    "root_i_newton = newton(f_i, x0=0.5, fprime=f_i_prime)  # начальная точка для i около 0.5\n",
    "root_e_newton = newton(f_e, x0=0.5)  # начальная точка для e около 0.5, но избегаем близости к разрывам\n",
    "\n",
    "root_i_bisect, root_i_newton, root_e_bisect, root_e_newton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e990ea85",
   "metadata": {
    "id": "wH0FmFPMuBMm"
   },
   "source": [
    "### 5. Зри в корень дважды\n",
    "\n",
    "Вычислить с точностью $\\varepsilon=10^{-3}$ координаты точек пересечения кривых (любых двух на ваш выбор двумя разными методами):\n",
    "\n",
    "a)\n",
    "$$\n",
    "\\left\\{\\begin{array}{l}\n",
    "\\sin (x+1)-y=1.2 \\\\\n",
    "2 x+\\cos (y)=2\n",
    "\\end{array}\\right.\n",
    "$$\n",
    "б)\n",
    "$$\n",
    "\\left\\{\\begin{array}{l}\n",
    "\\tan (x y+0.4)=x^2 \\\\\n",
    "0.6 x^2+2 y^2=1\n",
    "\\end{array}\\right.\n",
    "$$\n",
    "B)\n",
    "$$\n",
    "\\left\\{\\begin{array}{l}\n",
    "\\cos (x-1)+y=0.5 \\\\\n",
    "x-\\cos (y)=3\n",
    "\\end{array}\\right.\n",
    "$$\n",
    "г)\n",
    "$$\n",
    "\\left\\{\\begin{array}{l}\n",
    "\\sin (x+2)-y=1.5 \\\\\n",
    "x+\\cos (y-2)=0.5\n",
    "\\end{array}\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f75b9d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.5101495 , -0.20183784]),\n",
       " array([ 0.51015013, -0.2018384 ]),\n",
       " array([ 1.34633741, -1.70331696]),\n",
       " array([ 1.34636874, -1.70336398]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import fsolve\n",
    "\n",
    "# Выберем а) и г)\n",
    "epsilon = 1e-3\n",
    "\n",
    "def system_a(vars):\n",
    "    x, y = vars\n",
    "    return [np.sin(x + 1) - y - 1.2, 2 * x + np.cos(y) - 2]\n",
    "\n",
    "def system_g(vars):\n",
    "    x, y = vars\n",
    "    return [np.sin(x + 2) - y - 1.5, x + np.cos(y - 2) - 0.5]\n",
    "\n",
    "# Начальные приближения для каждой системы\n",
    "initial_guess_a = (0, 0)\n",
    "initial_guess_g = (0, 0)\n",
    "\n",
    "\n",
    "\n",
    "solution_a_1 = fsolve(system_a, initial_guess_a, xtol=epsilon)\n",
    "solution_a_2 = fsolve(system_a, (1, 1), xtol=epsilon)  # Другое начальное приближение\n",
    "\n",
    "\n",
    "solution_g_1 = fsolve(system_g, initial_guess_g, xtol=epsilon)\n",
    "solution_g_2 = fsolve(system_g, (1, 1), xtol=epsilon)  # Другое начальное приближение\n",
    "\n",
    "solution_a_1, solution_a_2, solution_g_1, solution_g_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb46130",
   "metadata": {
    "id": "M54t1xbyuBMm"
   },
   "source": [
    "### 6*. Оценка скорости сходимости метода Ньютона.\n",
    "Покажите, что для функции $f(x)=|x|^{5 / 2}$ метод Ньютона сходится лишь экспонциально - т.е. невязка уменьшается пропорционально $e^{-n}$.\n",
    "\n",
    "Покажите аналитически, что метод Ньютона в лучшем случае имеет квадратичную экспонциальную сходимость, т.е. ошибка убывает пропорционально $e^{-n^2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30cb8b1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "$f(x) = |x|^{5/2}$ , найдем первую производную:\n",
    "\n",
    "$f{\\prime}(x) = \\frac{5}{2} \\, |x|^{3/2} \\, \\operatorname{sgn}(x)$\n",
    "\n",
    "\n",
    "Применение формулы Ньютона\n",
    "\n",
    "При малых значениях  x ,  f(x)  и  $f{\\prime}(x) $ также малы, что замедляет сходимость. Для  x_n  достаточно близкого к нулю:\n",
    "\n",
    "$x_{n+1} = x_n - \\frac{|x_n|^{5/2}}{\\frac{5}{2} |x_n|^{3/2} \\operatorname{sgn}(x_n)} = x_n - \\frac{2}{5} |x_n| = \\left(1 - \\frac{2}{5}\\right) x_n = \\frac{3}{5} x_n$\n",
    "\n",
    "Это показывает, что:\n",
    "\n",
    "$|x_{n+1}| = \\frac{3}{5} |x_n|$\n",
    "\n",
    "\n",
    "Таким образом, на каждом шаге  $|x_n| $ уменьшается в геометрической прогрессии с коэффициентом $ \\frac{3}{5} $, что указывает на экспоненциальную сходимость:\n",
    "\n",
    "$|x_n| \\approx \\left(\\frac{3}{5}\\right)^n x_0$\n",
    "\n",
    "и ошибка убывает пропорционально $ e^{-n} $.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ab445b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
